{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54aa4bcc",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4a214",
   "metadata": {},
   "source": [
    "Q1 What is Simple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fbaa6",
   "metadata": {},
   "source": [
    "Definition: Simple Linear Regression is a statistical method used to model the relationship between two variables: one independent variable (X) and one dependent variable (Y). It assumes a linear relationship between the two variables.\n",
    "\n",
    "Equation: The relationship is represented by the equation:\n",
    "\n",
    "𝑌\n",
    "=\n",
    "𝑚\n",
    "𝑋\n",
    "+\n",
    "𝑐\n",
    "Y=mX+c\n",
    "where:\n",
    "\n",
    "𝑌\n",
    "Y is the dependent variable.\n",
    "𝑋\n",
    "X is the independent variable.\n",
    "𝑚\n",
    "m is the slope of the line (representing the change in \n",
    "𝑌\n",
    "Y for a unit change in \n",
    "𝑋\n",
    "X).\n",
    "𝑐\n",
    "c is the intercept (the value of \n",
    "𝑌\n",
    "Y when \n",
    "𝑋\n",
    "=\n",
    "0\n",
    "X=0).\n",
    "Purpose: The goal of simple linear regression is to find the best-fitting line (the line that minimizes the sum of squared differences between the observed and predicted values of \n",
    "𝑌\n",
    "Y).\n",
    "\n",
    "Applications: Simple linear regression is widely used for predictive modeling, trend analysis, and forecasting where the relationship between two variables is assumed to be linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb3c0c",
   "metadata": {},
   "source": [
    "Q2 What are the key assumptions of Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fe904",
   "metadata": {},
   "source": [
    "The key assumptions of Simple Linear Regression are:\n",
    "\n",
    "Linearity: The relationship between the independent variable (\n",
    "𝑋\n",
    "X) and the dependent variable (\n",
    "𝑌\n",
    "Y) is linear.\n",
    "\n",
    "Independence: The residuals (errors) are independent of each other.\n",
    "\n",
    "Homoscedasticity: The variance of residuals is constant across all levels of the independent variable (\n",
    "𝑋\n",
    "X).\n",
    "\n",
    "Normality of Residuals: The residuals are normally distributed.\n",
    "\n",
    "No Multicollinearity: Since this is simple linear regression, there should only be one predictor variable (\n",
    "𝑋\n",
    "X), so multicollinearity is not a concern here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15978ac8",
   "metadata": {},
   "source": [
    "Q3 What does the coefficient m represent in the equation Y=mX+c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9191c2c",
   "metadata": {},
   "source": [
    "Slope of the Line: The coefficient \n",
    "𝑚\n",
    "m represents the slope of the regression line in Simple Linear Regression. It indicates the change in the dependent variable (\n",
    "𝑌\n",
    "Y) for a one-unit increase in the independent variable (\n",
    "𝑋\n",
    "X).\n",
    "\n",
    "Direction of Relationship: If \n",
    "𝑚\n",
    "m is positive, \n",
    "𝑌\n",
    "Y increases as \n",
    "𝑋\n",
    "X increases (positive relationship). If \n",
    "𝑚\n",
    "m is negative, \n",
    "𝑌\n",
    "Y decreases as \n",
    "𝑋\n",
    "X increases (negative relationship).\n",
    "\n",
    "Magnitude of Change: The value of \n",
    "𝑚\n",
    "m quantifies the strength of the relationship. A larger absolute value of \n",
    "𝑚\n",
    "m means a steeper slope, indicating a greater change in \n",
    "𝑌\n",
    "Y for a given change in \n",
    "𝑋\n",
    "X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf2ad2",
   "metadata": {},
   "source": [
    "Q 4 What does the intercept c represent in the equation Y=mX+c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9bed42",
   "metadata": {},
   "source": [
    "In the equation \n",
    "𝑌\n",
    "=\n",
    "𝑚\n",
    "𝑋\n",
    "+\n",
    "𝑐\n",
    "Y=mX+c, the intercept \n",
    "𝑐\n",
    "c represents the y-intercept of the line.\n",
    "\n",
    "Meaning of \n",
    "𝑐\n",
    "c:\n",
    "It is the value of the dependent variable (\n",
    "𝑌\n",
    "Y) when the independent variable (\n",
    "𝑋\n",
    "X) is equal to 0.\n",
    "It indicates where the line crosses the \n",
    "𝑌\n",
    "Y-axis.\n",
    "Interpretation:\n",
    "The intercept \n",
    "𝑐\n",
    "c is the point on the \n",
    "𝑌\n",
    "Y-axis where the regression line starts when \n",
    "𝑋\n",
    "=\n",
    "0\n",
    "X=0.\n",
    "Example:\n",
    "If \n",
    "𝑐\n",
    "=\n",
    "5\n",
    "c=5, then when \n",
    "𝑋\n",
    "=\n",
    "0\n",
    "X=0, \n",
    "𝑌\n",
    "=\n",
    "5\n",
    "Y=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef83b39",
   "metadata": {},
   "source": [
    "Q5 How do we calculate the slope m in Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1e397",
   "metadata": {},
   "source": [
    "In Simple Linear Regression, the slope \n",
    "𝑚\n",
    "m (also known as the regression coefficient) represents the change in the dependent variable \n",
    "𝑦\n",
    "y for a one-unit change in the independent variable \n",
    "𝑥\n",
    "x. The formula for calculating the slope \n",
    "𝑚\n",
    "m is:\n",
    "\n",
    "𝑚\n",
    "=\n",
    "𝑛\n",
    "∑\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    "𝑦\n",
    "𝑖\n",
    ")\n",
    "−\n",
    "∑\n",
    "𝑥\n",
    "𝑖\n",
    "∑\n",
    "𝑦\n",
    "𝑖\n",
    "𝑛\n",
    "∑\n",
    "𝑥\n",
    "𝑖\n",
    "2\n",
    "−\n",
    "(\n",
    "∑\n",
    "𝑥\n",
    "𝑖\n",
    ")\n",
    "2\n",
    "m= \n",
    "n∑x \n",
    "i\n",
    "2\n",
    "​\n",
    " −(∑x \n",
    "i\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "n∑(x \n",
    "i\n",
    "​\n",
    " y \n",
    "i\n",
    "​\n",
    " )−∑x \n",
    "i\n",
    "​\n",
    " ∑y \n",
    "i\n",
    "​\n",
    " \n",
    "​\n",
    " \n",
    "Where:\n",
    "\n",
    "𝑛\n",
    "n is the number of data points.\n",
    "𝑥\n",
    "𝑖\n",
    "x \n",
    "i\n",
    "​\n",
    "  and \n",
    "𝑦\n",
    "𝑖\n",
    "y \n",
    "i\n",
    "​\n",
    "  are the individual data points of the independent and dependent variables, respectively.\n",
    "∑\n",
    "𝑥\n",
    "𝑖\n",
    "∑x \n",
    "i\n",
    "​\n",
    "  is the sum of all \n",
    "𝑥\n",
    "x values.\n",
    "∑\n",
    "𝑦\n",
    "𝑖\n",
    "∑y \n",
    "i\n",
    "​\n",
    "  is the sum of all \n",
    "𝑦\n",
    "y values.\n",
    "∑\n",
    "𝑥\n",
    "𝑖\n",
    "2\n",
    "∑x \n",
    "i\n",
    "2\n",
    "​\n",
    "  is the sum of the squares of all \n",
    "𝑥\n",
    "x values.\n",
    "∑\n",
    "𝑥\n",
    "𝑖\n",
    "𝑦\n",
    "𝑖\n",
    "∑x \n",
    "i\n",
    "​\n",
    " y \n",
    "i\n",
    "​\n",
    "  is the sum of the product of corresponding \n",
    "𝑥\n",
    "x and \n",
    "𝑦\n",
    "y values.\n",
    "\n",
    "Steps to calculate the slope:\n",
    "Calculate the sum of all \n",
    "𝑥\n",
    "x, \n",
    "𝑦\n",
    "y, \n",
    "𝑥\n",
    "2\n",
    "x \n",
    "2\n",
    " , and \n",
    "𝑥\n",
    "×\n",
    "𝑦\n",
    "x×y values.\n",
    "Substitute these sums into the formula.\n",
    "Solve for \n",
    "𝑚\n",
    "m, which is the slope of the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef751b6f",
   "metadata": {},
   "source": [
    "Q6 What is the purpose of the least squares method in Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b19c1",
   "metadata": {},
   "source": [
    "The Least Squares Method in Simple Linear Regression is used to find the best-fitting line (or regression line) through the data points. The purpose is to minimize the sum of the squared differences (errors) between the actual data points and the predicted values on the regression line. This method ensures that the line we fit to the data is the one that best represents the relationship between the independent variable (\n",
    "𝑥\n",
    "x) and the dependent variable (\n",
    "𝑦\n",
    "y).\n",
    "\n",
    "In summary, the Least Squares Method optimizes the parameters of the regression model by minimizing the total squared error between the observed and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf037c",
   "metadata": {},
   "source": [
    "Q7 How is the coefficient of determination (R²) interpreted in Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510dbd36",
   "metadata": {},
   "source": [
    "The coefficient of determination (R²) in Simple Linear Regression measures how well the regression line fits the data. It is interpreted as the proportion of the variance in the dependent variable (\n",
    "𝑌\n",
    "Y) that is explained by the independent variable (\n",
    "𝑋\n",
    "X).\n",
    "\n",
    "Formula:\n",
    "𝑅\n",
    "2\n",
    "=\n",
    "1\n",
    "−\n",
    "∑\n",
    "(\n",
    "𝑌\n",
    "𝑜\n",
    "𝑏\n",
    "𝑠\n",
    "𝑒\n",
    "𝑟\n",
    "𝑣\n",
    "𝑒\n",
    "𝑑\n",
    "−\n",
    "𝑌\n",
    "𝑝\n",
    "𝑟\n",
    "𝑒\n",
    "𝑑\n",
    "𝑖\n",
    "𝑐\n",
    "𝑡\n",
    "𝑒\n",
    "𝑑\n",
    ")\n",
    "2\n",
    "∑\n",
    "(\n",
    "𝑌\n",
    "𝑜\n",
    "𝑏\n",
    "𝑠\n",
    "𝑒\n",
    "𝑟\n",
    "𝑣\n",
    "𝑒\n",
    "𝑑\n",
    "−\n",
    "𝑌\n",
    "‾\n",
    ")\n",
    "2\n",
    "R \n",
    "2\n",
    " =1− \n",
    "∑(Y \n",
    "observed\n",
    "​\n",
    " − \n",
    "Y\n",
    " ) \n",
    "2\n",
    " \n",
    "∑(Y \n",
    "observed\n",
    "​\n",
    " −Y \n",
    "predicted\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "​\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "𝑌\n",
    "𝑜\n",
    "𝑏\n",
    "𝑠\n",
    "𝑒\n",
    "𝑟\n",
    "𝑣\n",
    "𝑒\n",
    "𝑑\n",
    "Y \n",
    "observed\n",
    "​\n",
    "  is the actual observed value of \n",
    "𝑌\n",
    "Y,\n",
    "𝑌\n",
    "𝑝\n",
    "𝑟\n",
    "𝑒\n",
    "𝑑\n",
    "𝑖\n",
    "𝑐\n",
    "𝑡\n",
    "𝑒\n",
    "𝑑\n",
    "Y \n",
    "predicted\n",
    "​\n",
    "  is the value predicted by the regression model,\n",
    "𝑌\n",
    "‾\n",
    "Y\n",
    "  is the mean of the observed \n",
    "𝑌\n",
    "Y-values.\n",
    "\n",
    "Interpretation:\n",
    "R² = 1: Perfect fit. All data points lie on the regression line, and the model explains all the variance in \n",
    "𝑌\n",
    "Y.\n",
    "R² = 0: The model does not explain any variance in \n",
    "𝑌\n",
    "Y. The predictions are as good as simply using the mean of \n",
    "𝑌\n",
    "Y.\n",
    "0 < R² < 1: A positive value indicates some level of explanatory power. For example, an \n",
    "𝑅\n",
    "2\n",
    "=\n",
    "0.8\n",
    "R \n",
    "2\n",
    " =0.8 means 80% of the variation in \n",
    "𝑌\n",
    "Y is explained by the model.\n",
    "\n",
    "Example:\n",
    "If \n",
    "𝑅\n",
    "2\n",
    "=\n",
    "0.85\n",
    "R \n",
    "2\n",
    " =0.85, it means that 85% of the variance in the dependent variable \n",
    "𝑌\n",
    "Y can be explained by the independent variable \n",
    "𝑋\n",
    "X, and the remaining 15% is unexplained or due to other factors.\n",
    "\n",
    "This is the complete interpretation of R² in Simple Linear Regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae09d55",
   "metadata": {},
   "source": [
    "Q8 What is Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4dbdce",
   "metadata": {},
   "source": [
    "Multiple Linear Regression (MLR) is a statistical technique used to model the relationship between one dependent variable and two or more independent variables. It extends simple linear regression by allowing multiple predictors to be included in the model.\n",
    "\n",
    "Equation:\n",
    "The general form of the equation for Multiple Linear Regression is:\n",
    "\n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "1\n",
    "+\n",
    "𝑏\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "+\n",
    "𝜖\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X \n",
    "1\n",
    "​\n",
    " +b \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    "​\n",
    " +⋯+b \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    "​\n",
    " +ϵ\n",
    "\n",
    "Purpose:\n",
    "The goal of Multiple Linear Regression is to estimate the relationship between the dependent variable and multiple predictors, making it possible to predict \n",
    "𝑌\n",
    "Y based on the values of \n",
    "𝑋\n",
    "1\n",
    ",\n",
    "𝑋\n",
    "2\n",
    ",\n",
    "…\n",
    ",\n",
    "𝑋\n",
    "𝑛\n",
    "X \n",
    "1\n",
    "​\n",
    " ,X \n",
    "2\n",
    "​\n",
    " ,…,X \n",
    "n\n",
    "​\n",
    " .\n",
    "\n",
    "Example:\n",
    "Predicting the price of a house (\n",
    "𝑌\n",
    "Y) based on factors such as size (\n",
    "𝑋\n",
    "1\n",
    "X \n",
    "1\n",
    "​\n",
    " ), number of bedrooms (\n",
    "𝑋\n",
    "2\n",
    "X \n",
    "2\n",
    "​\n",
    " ), and location (\n",
    "𝑋\n",
    "3\n",
    "X \n",
    "3\n",
    "​\n",
    " ). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86caba64",
   "metadata": {},
   "source": [
    "Q9 What is the main difference between Simple and Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56014a",
   "metadata": {},
   "source": [
    "The main difference between Simple Linear Regression and Multiple Linear Regression lies in the number of independent variables used to predict the dependent variable.\n",
    "\n",
    "1. Number of Independent Variables:\n",
    "    \n",
    "Simple Linear Regression: Uses one independent variable (predictor) to predict the dependent variable.\n",
    "𝑌\n",
    "=\n",
    "𝑚\n",
    "𝑋\n",
    "+\n",
    "𝑐\n",
    "Y=mX+c\n",
    "\n",
    "Multiple Linear Regression: Uses two or more independent variables to predict the dependent variable.\n",
    "    \n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "1\n",
    "+\n",
    "𝑏\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "+\n",
    "𝜖\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X \n",
    "1\n",
    "​\n",
    " +b \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    "​\n",
    " +⋯+b \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    "​\n",
    " +ϵ\n",
    "    \n",
    "2. Complexity:\n",
    "Simple Linear Regression: The relationship between the dependent and independent variable is modeled as a straight line.\n",
    "Multiple Linear Regression: Models the relationship as a hyperplane in higher-dimensional space, allowing for more complex relationships between variables.\n",
    "    \n",
    "3. Application:\n",
    "Simple Linear Regression: Applied when you want to assess how one predictor affects the dependent variable.\n",
    "Multiple Linear Regression: Used when you want to understand the impact of multiple predictors on the dependent variable, considering their combined effect.\n",
    "    \n",
    "Example:\n",
    "Simple Linear Regression: Predicting the price of a house based on its size (one variable).\n",
    "Multiple Linear Regression: Predicting the price of a house based on size, number of bedrooms, and location (multiple variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4c989",
   "metadata": {},
   "source": [
    "Q10 What are the key assumptions of Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccae395",
   "metadata": {},
   "source": [
    "Linearity: The relationship between the predictors and the dependent variable is linear.\n",
    "    \n",
    "Independence of errors: The residuals (errors) should be independent.\n",
    "    \n",
    "Homoscedasticity: Constant variance of errors.\n",
    "    \n",
    "Normality of residuals: Residuals should be normally distributed.\n",
    "    \n",
    "No multicollinearity: Predictors should not be highly correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cebaf2e",
   "metadata": {},
   "source": [
    "Q11 What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72289f",
   "metadata": {},
   "source": [
    "Heteroscedasticity refers to the condition where the variance of the residuals (errors) in a regression model is not constant across all levels of the independent variables. In other words, the spread of the residuals increases or decreases as the values of the independent variables change.\n",
    "\n",
    "Impact on Multiple Linear Regression:\n",
    "\n",
    "Biased Standard Errors: The OLS estimates of regression coefficients are still unbiased, but the standard errors become inefficient, leading to unreliable hypothesis tests.\n",
    "    \n",
    "Misleading Significance Levels: The p-values associated with the regression coefficients may be distorted, leading to incorrect conclusions about the significance of predictors.\n",
    "    \n",
    "Invalid Confidence Intervals: The confidence intervals for the regression coefficients may become either too wide or too narrow, affecting the precision of the estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21384fd",
   "metadata": {},
   "source": [
    "Q12 How can you improve a Multiple Linear Regression model with high multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810da75",
   "metadata": {},
   "source": [
    "Remove Highly Correlated Predictors: Identify and remove one of the predictors that are highly correlated using the correlation matrix or Variance Inflation Factor (VIF).\n",
    "\n",
    "Use Regularization Techniques: Apply Ridge Regression (L2) or Lasso Regression (L1) to shrink coefficients and reduce multicollinearity.\n",
    "    \n",
    "\n",
    "Increase Sample Size: A larger dataset can help reduce the effects of multicollinearity by providing more reliable estimates.\n",
    "    \n",
    "\n",
    "Apply Principal Component Analysis (PCA): Use PCA to combine correlated predictors into uncorrelated components, simplifying the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6faa99",
   "metadata": {},
   "source": [
    "Q13 What are some common techniques for transforming categorical variables for use in regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3955d",
   "metadata": {},
   "source": [
    "One-Hot Encoding: Creates binary (0 or 1) columns for each category in the categorical variable, allowing the model to handle non-numeric data without assuming any order.\n",
    "\n",
    "Label Encoding: Assigns a unique integer to each category. This method is best used when the categorical variable has a natural ordinal relationship (e.g., \"low\", \"medium\", \"high\").\n",
    "    \n",
    "\n",
    "Binary Encoding: Converts categorical variables into binary format, useful for variables with many categories, reducing the dimensionality compared to one-hot encoding.\n",
    "    \n",
    "\n",
    "Target Encoding (Mean Encoding): Replaces categories with the mean of the target variable for each category. This can be useful for high-cardinality features but may lead to overfitting if not handled carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b3d21",
   "metadata": {},
   "source": [
    "Q14 What is the role of interaction terms in Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785572da",
   "metadata": {},
   "source": [
    "Capturing Combined Effects: Interaction terms allow the model to account for the combined effect of two or more independent variables on the dependent variable, which cannot be captured by the individual predictors alone.\n",
    "\n",
    "Improving Model Fit: Including interaction terms can improve the model by explaining variations in the dependent variable that occur due to the interaction between predictors, leading to better predictions.\n",
    "\n",
    "Identifying Synergistic Relationships: Interaction terms help identify whether the effect of one independent variable on the dependent variable changes at different levels of another independent variable.\n",
    "\n",
    "Enhancing Interpretability: Including interactions improves the understanding of how different variables work together, rather than assuming they only have independent, additive effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872f2dd",
   "metadata": {},
   "source": [
    "Q15 How can the interpretation of intercept differ between Simple and Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681e1f8",
   "metadata": {},
   "source": [
    "Simple Linear Regression: The intercept (\n",
    "𝑐\n",
    "c) represents the value of the dependent variable (\n",
    "𝑌\n",
    "Y) when the independent variable (\n",
    "𝑋\n",
    "X) is zero. It is the point where the regression line crosses the \n",
    "𝑌\n",
    "Y-axis.\n",
    "\n",
    "Multiple Linear Regression: The intercept (\n",
    "𝑏\n",
    "0\n",
    "b \n",
    "0\n",
    "​\n",
    " ) represents the value of the dependent variable (\n",
    "𝑌\n",
    "Y) when all independent variables (\n",
    "𝑋\n",
    "1\n",
    ",\n",
    "𝑋\n",
    "2\n",
    ",\n",
    "…\n",
    ",\n",
    "𝑋\n",
    "𝑛\n",
    "X \n",
    "1\n",
    "​\n",
    " ,X \n",
    "2\n",
    "​\n",
    " ,…,X \n",
    "n\n",
    "​\n",
    " ) are zero. It is the baseline value when all predictors are at their reference levels.\n",
    "\n",
    "Context in Simple Regression: In Simple Linear Regression, the intercept is interpreted in the context of a single predictor and its relationship with \n",
    "𝑌\n",
    "Y.\n",
    "\n",
    "Context in Multiple Regression: In Multiple Linear Regression, the intercept is interpreted in the context of multiple predictors. It represents the expected value of \n",
    "𝑌\n",
    "Y when all predictors are set to their baseline or reference values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960c5c0",
   "metadata": {},
   "source": [
    "Q16 What is the significance of the slope in regression analysis, and how does it affect predictions\u001d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512afea",
   "metadata": {},
   "source": [
    "The slope in regression analysis represents the relationship between the independent variable(s) and the dependent variable. Specifically, it quantifies how much the dependent variable \n",
    "𝑌\n",
    "Y changes for a one-unit change in the independent variable(s) \n",
    "𝑋\n",
    "X.\n",
    "\n",
    "Represents Relationship: The slope (\n",
    "𝑚\n",
    "m) in regression analysis represents the rate of change of the dependent variable (\n",
    "𝑌\n",
    "Y) for a one-unit change in the independent variable (\n",
    "𝑋\n",
    "X).\n",
    "\n",
    "Direction of Effect: A positive slope indicates a direct relationship (as \n",
    "𝑋\n",
    "X increases, \n",
    "𝑌\n",
    "Y increases), while a negative slope indicates an inverse relationship (as \n",
    "𝑋\n",
    "X increases, \n",
    "𝑌\n",
    "Y decreases).\n",
    "\n",
    "Magnitude of Impact: The magnitude of the slope shows how sensitive the dependent variable is to changes in the independent variable. A larger slope means a greater impact of \n",
    "𝑋\n",
    "X on \n",
    "𝑌\n",
    "Y.\n",
    "\n",
    "Prediction Influence: The slope directly influences predictions, as it determines how much the predicted value of \n",
    "𝑌\n",
    "Y changes for a given change in \n",
    "𝑋\n",
    "X, allowing the model to make more accurate forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31ae54",
   "metadata": {},
   "source": [
    "Q17 How does the intercept in a regression model provide context for the relationship between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3de7b",
   "metadata": {},
   "source": [
    "Baseline Value: The intercept (\n",
    "𝑐\n",
    "c) represents the value of the dependent variable (\n",
    "𝑌\n",
    "Y) when all independent variables (\n",
    "𝑋\n",
    "1\n",
    ",\n",
    "𝑋\n",
    "2\n",
    ",\n",
    "…\n",
    ",\n",
    "𝑋\n",
    "𝑛\n",
    "X \n",
    "1\n",
    "​\n",
    " ,X \n",
    "2\n",
    "​\n",
    " ,…,X \n",
    "n\n",
    "​\n",
    " ) are equal to zero. It provides a reference point or starting value for the relationship between the variables.\n",
    "\n",
    "Context for Predictions: The intercept helps to understand the baseline prediction of \n",
    "𝑌\n",
    "Y before any independent variables contribute to the outcome. It sets the foundation for the model's predictions.\n",
    "\n",
    "Interpretation in Multiple Regression: In the context of multiple regression, the intercept represents the predicted value of \n",
    "𝑌\n",
    "Y when all predictors are at their baseline or reference levels (e.g., when all variables are zero, or in the case of categorical variables, at their reference category).\n",
    "\n",
    "Understanding the Relationship: While the intercept itself may not always have meaningful real-world interpretation, it provides the necessary context for how changes in the independent variables will influence the dependent variable as the model’s prediction evolves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bc226",
   "metadata": {},
   "source": [
    "Q18 What are the limitations of using R² as a sole measure of model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608de810",
   "metadata": {},
   "source": [
    "Doesn't Indicate Model Accuracy: R² only measures the proportion of the variance in the dependent variable explained by the independent variables, but it does not tell you how accurate the model’s predictions are.\n",
    "\n",
    "Sensitive to Overfitting: A higher R² can result from overfitting, especially in models with many predictors. Even if the model fits the data well, it may not generalize to new, unseen data.\n",
    "\n",
    "No Information on Causality: R² measures correlation, not causality. A high R² does not imply that the independent variables cause changes in the dependent variable.\n",
    "\n",
    "Cannot Assess Model Complexity: R² increases with the addition of more predictors, even if they are not meaningful. It doesn’t penalize the inclusion of irrelevant variables, which can lead to misleading conclusions about the model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d32c1f",
   "metadata": {},
   "source": [
    "Q19 How would you interpret a large standard error for a regression coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc5c6a",
   "metadata": {},
   "source": [
    "Uncertainty in the Estimate: A large standard error indicates high uncertainty about the value of the regression coefficient. This suggests that the estimated coefficient is not very precise.\n",
    "\n",
    "Potential for Insignificance: A large standard error can result in a t-statistic that is too small, leading to a non-significant p-value. This means that the predictor may not have a strong relationship with the dependent variable.\n",
    "\n",
    "Multicollinearity Issues: A large standard error may indicate multicollinearity in the model, where the independent variables are highly correlated with each other. This can make it difficult to isolate the effect of individual predictors.\n",
    "\n",
    "Model Instability: A large standard error suggests that the model might be unstable or that there is insufficient data or variability in the independent variable to accurately estimate the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c23507",
   "metadata": {},
   "source": [
    "Q20 How can heteroscedasticity be identified in residual plots, and why is it important to address it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762f8da",
   "metadata": {},
   "source": [
    "Identification in Residual Plots: Heteroscedasticity can be identified in residual plots when the spread (variance) of residuals increases or decreases as the fitted values (predicted values of \n",
    "𝑌\n",
    "Y) change. This pattern appears as a \"fan-shaped\" or \"cone-shaped\" spread of residuals.\n",
    "\n",
    "Patterns in Residuals: If the residuals are randomly scattered around the horizontal axis with no clear pattern, it suggests homoscedasticity. However, if the residuals show a clear trend or change in variance, it indicates heteroscedasticity.\n",
    "\n",
    "Importance of Addressing Heteroscedasticity: Heteroscedasticity affects the efficiency of coefficient estimates by making them less reliable. It leads to biased standard errors, which distort hypothesis tests (e.g., incorrect p-values), and reduces the precision of predictions.\n",
    "\n",
    "Model Improvement: Addressing heteroscedasticity, typically through transformations (e.g., log transformations), weighted least squares regression, or robust standard errors, improves the reliability and validity of the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e67f4",
   "metadata": {},
   "source": [
    "Q21 What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f684c6e",
   "metadata": {},
   "source": [
    "Overfitting: A high R² with a low adjusted R² suggests that the model may be overfitting the data. This means the model fits the training data very well, but the inclusion of many predictors may not improve the model’s generalizability to new data.\n",
    "\n",
    "Irrelevant Variables: The model likely includes irrelevant or unnecessary predictors, which increase the R² but do not contribute significantly to explaining the variation in the dependent variable. Adjusted R² penalizes this overfitting by adjusting for the number of predictors.\n",
    "\n",
    "Model Complexity: While R² increases with more predictors, adjusted R² accounts for model complexity and rewards models that generalize better by providing a more conservative measure of fit.\n",
    "\n",
    "Need for Model Refinement: A high R² and low adjusted R² indicate that the model needs refinement, such as removing unnecessary predictors or applying regularization techniques, to improve predictive accuracy and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f52300",
   "metadata": {},
   "source": [
    "Q22 Why is it important to scale variables in Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f74899",
   "metadata": {},
   "source": [
    "Improves Model Convergence: Scaling variables helps the optimization algorithm converge faster, especially in models that rely on gradient-based methods, by preventing one variable from dominating the others due to differing units or magnitudes.\n",
    "\n",
    "Equal Contribution of Variables: When variables are on different scales, those with larger numerical ranges can disproportionately affect the regression coefficients. Scaling ensures that each variable contributes equally to the model.\n",
    "\n",
    "Regularization: In models with regularization techniques like Ridge or Lasso regression, scaling is crucial because the penalty terms are sensitive to the magnitude of the coefficients. Without scaling, variables with larger scales may be penalized more heavily.\n",
    "\n",
    "Interpretation of Coefficients: Scaling makes it easier to interpret the coefficients, as they represent the effect of a one-unit change in the standardized variable, rather than being influenced by the variable’s original scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78eaf4d",
   "metadata": {},
   "source": [
    "Q23 What is polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7f10a",
   "metadata": {},
   "source": [
    "Polynomial Regression is a type of regression analysis used when the relationship between the independent variable(s) and the dependent variable is modeled as an nth-degree polynomial rather than a straight line. This allows for capturing more complex, non-linear relationships between the variables.\n",
    "\n",
    "Equation:\n",
    "    \n",
    "The general form of a polynomial regression model for one independent variable \n",
    "𝑋\n",
    "X is:\n",
    "\n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "+\n",
    "𝑏\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "𝑏\n",
    "3\n",
    "𝑋\n",
    "3\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "+\n",
    "𝜖\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X+b \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    " +b \n",
    "3\n",
    "​\n",
    " X \n",
    "3\n",
    " +⋯+b \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    " +ϵ\n",
    "    \n",
    "Conclusion:\n",
    "Polynomial regression is a powerful tool for modeling non-linear relationships. By introducing polynomial terms, it can capture curvatures and complex patterns that a simple linear model cannot. However, care must be taken to avoid overfitting and to choose an appropriate degree for the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88990e4",
   "metadata": {},
   "source": [
    "Q24 How does polynomial regression differ from linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc09ce",
   "metadata": {},
   "source": [
    "Model Type: Linear regression models the relationship between the independent variable (\n",
    "𝑋\n",
    "X) and the dependent variable (\n",
    "𝑌\n",
    "Y) as a straight line, while polynomial regression models it as a curve (polynomial of degree \n",
    "𝑛\n",
    "n).\n",
    "\n",
    "Equation Structure: In linear regression, the equation is \n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X, where \n",
    "𝑏\n",
    "0\n",
    "b \n",
    "0\n",
    "​\n",
    "  and \n",
    "𝑏\n",
    "1\n",
    "b \n",
    "1\n",
    "​\n",
    "  are coefficients. In polynomial regression, the equation includes higher-degree terms such as \n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "+\n",
    "𝑏\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X+b \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    " +⋯+b \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    " , allowing the model to fit curves.\n",
    "\n",
    "Handling Nonlinearity: Linear regression is suitable for modeling linear relationships, whereas polynomial regression is used to capture nonlinear relationships, making it more flexible when the data has a curved pattern.\n",
    "\n",
    "Model Complexity: Polynomial regression can become more complex and prone to overfitting as the degree of the polynomial increases, while linear regression remains simpler and more stable with fewer parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b4a26",
   "metadata": {},
   "source": [
    "Q25 When is polynomial regression used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903fb2c",
   "metadata": {},
   "source": [
    "Nonlinear Relationships: Polynomial regression is used when the relationship between the independent and dependent variables is nonlinear, and a linear regression model does not capture the underlying pattern effectively.\n",
    "\n",
    "Curved Data Patterns: It is ideal when the data shows a curved trend (e.g., quadratic, cubic), which linear regression cannot model due to its assumption of a straight-line relationship.\n",
    "\n",
    "Improving Model Fit: Polynomial regression is applied when adding higher-degree terms improves the model's ability to fit complex data, such as when small variations in the data are significant.\n",
    "\n",
    "Flexible Modeling: It is used in scenarios where flexibility is needed to model relationships that are not strictly linear but still follow a smooth curve, like in economics, biology, or engineering data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa870f6",
   "metadata": {},
   "source": [
    "Q26 What is the general equation for polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88884c21",
   "metadata": {},
   "source": [
    "The general equation for polynomial regression is:\n",
    "\n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "+\n",
    "𝑏\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "𝑏\n",
    "3\n",
    "𝑋\n",
    "3\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X+b \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    " +b \n",
    "3\n",
    "​\n",
    " X \n",
    "3\n",
    " +⋯+b \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    " \n",
    "Where:\n",
    "\n",
    "𝑌\n",
    "Y is the dependent variable.\n",
    "𝑋\n",
    "X is the independent variable.\n",
    "𝑏\n",
    "0\n",
    ",\n",
    "𝑏\n",
    "1\n",
    ",\n",
    "…\n",
    ",\n",
    "𝑏\n",
    "𝑛\n",
    "b \n",
    "0\n",
    "​\n",
    " ,b \n",
    "1\n",
    "​\n",
    " ,…,b \n",
    "n\n",
    "​\n",
    "  are the coefficients (parameters) to be estimated.\n",
    "𝑛\n",
    "n is the degree of the polynomial (e.g., \n",
    "𝑛\n",
    "=\n",
    "2\n",
    "n=2 for quadratic, \n",
    "𝑛\n",
    "=\n",
    "3\n",
    "n=3 for cubic).\n",
    "\n",
    "This equation allows for fitting a curve (polynomial) to the data, capturing more complex relationships than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab81957",
   "metadata": {},
   "source": [
    "Q27 Can polynomial regression be applied to multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278a21b",
   "metadata": {},
   "source": [
    "Yes, Polynomial Regression Can Be Extended: Polynomial regression can be applied to multiple variables by using interaction terms and higher-degree terms for each independent variable.\n",
    "\n",
    "General Form: For multiple variables, the equation becomes:\n",
    "\n",
    "𝑌\n",
    "=\n",
    "𝑏\n",
    "0\n",
    "+\n",
    "𝑏\n",
    "1\n",
    "𝑋\n",
    "1\n",
    "+\n",
    "𝑏\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "+\n",
    "1\n",
    "𝑋\n",
    "1\n",
    "2\n",
    "+\n",
    "𝑏\n",
    "𝑛\n",
    "+\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "2\n",
    "+\n",
    "…\n",
    "Y=b \n",
    "0\n",
    "​\n",
    " +b \n",
    "1\n",
    "​\n",
    " X \n",
    "1\n",
    "​\n",
    " +b \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    "​\n",
    " +⋯+b \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    "​\n",
    " +b \n",
    "n+1\n",
    "​\n",
    " X \n",
    "1\n",
    "2\n",
    "​\n",
    " +b \n",
    "n+2\n",
    "​\n",
    " X \n",
    "2\n",
    "2\n",
    "​\n",
    " +…\n",
    "Where \n",
    "𝑋\n",
    "1\n",
    ",\n",
    "𝑋\n",
    "2\n",
    ",\n",
    "…\n",
    ",\n",
    "𝑋\n",
    "𝑛\n",
    "X \n",
    "1\n",
    "​\n",
    " ,X \n",
    "2\n",
    "​\n",
    " ,…,X \n",
    "n\n",
    "​\n",
    "  are the independent variables, and the equation includes polynomial terms for each variable, as well as interactions between them.\n",
    "\n",
    "Interaction Terms: Polynomial regression with multiple variables also includes interaction terms, such as \n",
    "𝑋\n",
    "1\n",
    "𝑋\n",
    "2\n",
    "X \n",
    "1\n",
    "​\n",
    " X \n",
    "2\n",
    "​\n",
    " , \n",
    "𝑋\n",
    "1\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "X \n",
    "1\n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    "​\n",
    " , etc., to model relationships where variables interact.\n",
    "\n",
    "More Complex Models: As the number of variables and the degree of the polynomial increases, the model becomes more complex and flexible, allowing it to capture intricate relationships in multidimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cd54a",
   "metadata": {},
   "source": [
    "Q28 What are the limitations of polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b963b",
   "metadata": {},
   "source": [
    "Overfitting: Polynomial regression can easily overfit the data, especially when using higher-degree polynomials. The model may fit the training data very well but perform poorly on new, unseen data due to excessive complexity.\n",
    "\n",
    "Increased Model Complexity: As the degree of the polynomial increases, the model becomes more complex, which can lead to difficulties in interpretation and slower computations, especially with large datasets.\n",
    "\n",
    "Sensitivity to Outliers: Polynomial regression is highly sensitive to outliers, which can significantly affect the fit of the model and lead to inaccurate predictions.\n",
    "\n",
    "Extrapolation Issues: Polynomial regression can struggle with extrapolation, as the model might not behave predictably outside the range of the training data, leading to unrealistic predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0a4f5",
   "metadata": {},
   "source": [
    "Q29 What methods can be used to evaluate model fit when selecting the degree of a polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdb1eb",
   "metadata": {},
   "source": [
    "Cross-Validation: Cross-validation, particularly k-fold cross-validation, can be used to assess how well the model generalizes to unseen data. By testing different polynomial degrees, you can choose the one that minimizes validation error and avoids overfitting.\n",
    "\n",
    "Adjusted R²: Unlike R², adjusted R² penalizes the inclusion of unnecessary predictors or higher-degree terms, providing a more reliable evaluation of model fit when selecting the degree of a polynomial.\n",
    "\n",
    "Akaike Information Criterion (AIC) / Bayesian Information Criterion (BIC): These criteria help to balance model fit and complexity. A lower AIC or BIC indicates a better model, taking both goodness-of-fit and the number of parameters into account.\n",
    "\n",
    "Residual Plots: Analyzing residual plots helps to detect any patterns in the residuals that might suggest a poor fit. Ideally, residuals should be randomly distributed. If patterns persist, it might indicate that the degree of the polynomial is either too high or too low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b785ef1",
   "metadata": {},
   "source": [
    "Q30 Why is visualization important in polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f7cd7",
   "metadata": {},
   "source": [
    "Understanding Model Fit: Visualization helps to visually assess how well the polynomial model fits the data. By plotting both the original data points and the polynomial regression curve, you can easily see if the model captures the underlying trends.\n",
    "\n",
    "Detecting Overfitting: Visualization allows you to spot overfitting, especially when higher-degree polynomials produce curves that excessively fit the noise in the data rather than the actual trend. This helps in selecting the optimal degree of the polynomial.\n",
    "\n",
    "Identifying Patterns: It provides a clear representation of how the dependent variable changes with respect to the independent variable(s), revealing nonlinear relationships and making it easier to interpret complex interactions between variables.\n",
    "\n",
    "Model Diagnostics: Visualizing residuals (such as in residual plots) can help in detecting issues like heteroscedasticity, outliers, or misspecification of the model, allowing you to improve the model accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa5b5b",
   "metadata": {},
   "source": [
    "Q31 How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56354eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create sample data (X as independent variable, y as dependent variable)\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
    "y = np.array([1, 4, 9, 16, 25])  # Dependent variable (quadratic relationship with X)\n",
    "\n",
    "# Step 1: Transform the independent variable X into polynomial features (degree 2 in this case)\n",
    "poly = PolynomialFeatures(degree=2)  # Degree of the polynomial\n",
    "X_poly = poly.fit_transform(X)  # Transforms X into a higher-degree polynomial\n",
    "\n",
    "# Step 2: Create and fit a linear regression model to the polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Step 4: Visualize the results (original data points and the polynomial regression curve)\n",
    "plt.scatter(X, y, color='red', label='Original data')  # Scatter plot of original data\n",
    "plt.plot(X, y_pred, color='blue', label='Polynomial regression line')  # Polynomial regression curve\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6fcda",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "    \n",
    "Data: We use a simple quadratic relationship between \n",
    "𝑋\n",
    "X and \n",
    "𝑦\n",
    "y (i.e., \n",
    "𝑦\n",
    "=\n",
    "𝑋\n",
    "2\n",
    "y=X \n",
    "2\n",
    " ).\n",
    "PolynomialFeatures(degree=2): Transforms \n",
    "𝑋\n",
    "X into a new feature set with degree 2, meaning it adds the square of \n",
    "𝑋\n",
    "X as an additional feature.\n",
    "\n",
    "LinearRegression(): The linear regression model is fitted on the transformed polynomial features.\n",
    "    \n",
    "Visualization: The red dots represent the original data points, while the blue line is the polynomial regression model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3572be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
